{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "23101dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import tất cả các thư viện cần thiết\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import sqlite3\n",
    "import os\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e1388e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thiết lập CUDA_LAUNCH_BLOCKING để gỡ lỗi CUDA\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "568d4488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Định nghĩa Dataset\n",
    "class M5MultiDataset(Dataset):\n",
    "    def __init__(self, data, cols, window_size):\n",
    "        self.data = data\n",
    "        self.cols = cols\n",
    "        self.win = window_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.win\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        slice_ = self.data.iloc[idx:idx+self.win]\n",
    "        X_num = torch.FloatTensor(slice_[self.cols].values)\n",
    "        X_item = torch.LongTensor(slice_['item_idx'].values)\n",
    "        X_store = torch.LongTensor(slice_['store_idx'].values)\n",
    "        y = torch.FloatTensor([self.data['sales'].iloc[idx+self.win]]).squeeze()\n",
    "        return X_num, X_item, X_store, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "77fcb0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Định nghĩa mô hình LSTM\n",
    "class LSTMEmbForecast(nn.Module):\n",
    "    def __init__(self, n_items, n_stores, embed_dim, num_feats, hidden_size, num_layers=1, dropout=0.25):\n",
    "        super().__init__()\n",
    "        self.item_emb = nn.Embedding(n_items, embed_dim)\n",
    "        self.store_emb = nn.Embedding(n_stores, embed_dim)\n",
    "        input_size = embed_dim * 2 + num_feats\n",
    "        self.feat_fc = nn.Linear(num_feats, num_feats * 2)\n",
    "        self.lstm = nn.LSTM(input_size + num_feats, hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, X_num, X_item, X_store):\n",
    "        item_emb = self.item_emb(X_item)\n",
    "        store_emb = self.store_emb(X_store)\n",
    "        X_num_transformed = self.feat_fc(X_num)\n",
    "        X = torch.cat((X_num_transformed, item_emb, store_emb), dim=-1)\n",
    "        lstm_out, _ = self.lstm(X)\n",
    "        lstm_out = self.dropout(lstm_out)\n",
    "        out = self.fc(lstm_out[:, -1, :])\n",
    "        return out.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0a3a92e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm huấn luyện mô hình\n",
    "def train_model(model, train_loader, val_loader, num_epochs=20, lr=0.0008, device='cpu', patience=5):\n",
    "    model = model.to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_preds, train_targets = [], []\n",
    "        for X_num, X_item, X_store, y in train_loader:\n",
    "            X_num, X_item, X_store, y = X_num.to(device), X_item.to(device), X_store.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(X_num, X_item, X_store)\n",
    "            loss = criterion(out, y)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            train_preds.extend(out.cpu().detach().numpy())\n",
    "            train_targets.extend(y.cpu().detach().numpy())\n",
    "        train_loss /= len(train_loader)\n",
    "        train_mae = mean_absolute_error(train_targets, train_preds)\n",
    "        train_r2 = r2_score(train_targets, train_preds)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_preds, val_targets = [], []\n",
    "        with torch.no_grad():\n",
    "            for X_num, X_item, X_store, y in val_loader:\n",
    "                X_num, X_item, X_store, y = X_num.to(device), X_item.to(device), X_store.to(device), y.to(device)\n",
    "                out = model(X_num, X_item, X_store)\n",
    "                loss = criterion(out, y)\n",
    "                val_loss += loss.item()\n",
    "                val_preds.extend(out.cpu().detach().numpy())\n",
    "                val_targets.extend(y.cpu().detach().numpy())\n",
    "        val_loss /= len(val_loader)\n",
    "        val_mae = mean_absolute_error(val_targets, val_preds)\n",
    "        val_r2 = r2_score(val_targets, val_preds)\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Train MAE: {train_mae:.4f}, Val MAE: {val_mae:.4f}, Train R2: {train_r2:.4f}, Val R2: {val_r2:.4f}')\n",
    "        \n",
    "        # Early stopping với patience\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'model.pth')\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            print(f\"No improvement in Val Loss for {epochs_no_improve} epoch(s).\")\n",
    "            if epochs_no_improve >= patience:\n",
    "                print(f\"Early stopping after {epoch+1} epochs...\")\n",
    "                break\n",
    "        \n",
    "        # Giảm learning rate nếu Val Loss không cải thiện\n",
    "        scheduler.step(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0962f9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for all states...\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Huấn luyện mô hình duy nhất\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Training model for all states...\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "49c80ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đọc dữ liệu từ SQLite\n",
    "df = pd.read_sql_query(\"SELECT * FROM data\", sqlite3.connect('processed_data.db'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9a23912a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min item_idx: 0\n",
      "Max item_idx: 43\n",
      "Min store_idx: 0\n",
      "Max store_idx: 9\n"
     ]
    }
   ],
   "source": [
    "# Kiểm tra giá trị của item_idx và store_idx\n",
    "print(\"Min item_idx:\", df['item_idx'].min())\n",
    "print(\"Max item_idx:\", df['item_idx'].max())\n",
    "print(\"Min store_idx:\", df['store_idx'].min())\n",
    "print(\"Max store_idx:\", df['store_idx'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c9dbbc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chia dữ liệu thành train và val\n",
    "split = int(len(df) * 0.8)\n",
    "df_train, df_val = df.iloc[:split], df.iloc[split:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "047cd720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo Dataset và DataLoader\n",
    "feature_cols = ['day', 'weekday_sin', 'weekday_cos', 'month_sin', 'month_cos', 'week',\n",
    "                'sales_lag_7', 'sales_lag_14', 'sales_lag_28', 'rolling_mean_7', 'rolling_mean_14',\n",
    "                'sell_price', 'event', 'snap']\n",
    "window_size = 28\n",
    "batch_size = 64\n",
    "\n",
    "train_ds = M5MultiDataset(df_train, feature_cols, window_size=window_size)\n",
    "val_ds = M5MultiDataset(df_val, feature_cols, window_size=window_size)\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fbda2366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_items: 44, num_stores: 10\n"
     ]
    }
   ],
   "source": [
    "# Khởi tạo mô hình\n",
    "num_items = len(pd.read_sql_query(\"SELECT DISTINCT item_idx FROM data\", sqlite3.connect('processed_data.db')))\n",
    "num_stores = len(pd.read_sql_query(\"SELECT DISTINCT store_idx FROM data\", sqlite3.connect('processed_data.db')))\n",
    "print(f\"num_items: {num_items}, num_stores: {num_stores}\")\n",
    "\n",
    "# Kiểm tra xem các giá trị có hợp lệ không\n",
    "if df['item_idx'].max() >= num_items:\n",
    "    raise ValueError(\"item_idx contains values larger than or equal to num_items!\")\n",
    "if df['store_idx'].max() >= num_stores:\n",
    "    raise ValueError(\"store_idx contains values larger than or equal to num_stores!\")\n",
    "if df['item_idx'].min() < 0:\n",
    "    raise ValueError(\"item_idx contains negative values!\")\n",
    "if df['store_idx'].min() < 0:\n",
    "    raise ValueError(\"store_idx contains negative values!\")\n",
    "\n",
    "model = LSTMEmbForecast(\n",
    "    n_items=num_items,\n",
    "    n_stores=num_stores,\n",
    "    embed_dim=16,\n",
    "    num_feats=len(feature_cols),\n",
    "    hidden_size=64,\n",
    "    num_layers=2,\n",
    "    dropout=0.25\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "db356e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Train Loss: 0.0008, Val Loss: 0.0004, Train MAE: 0.0148, Val MAE: 0.0096, Train R2: 0.5797, Val R2: 0.7693\n",
      "Epoch 2/20, Train Loss: 0.0005, Val Loss: 0.0005, Train MAE: 0.0110, Val MAE: 0.0101, Train R2: 0.7236, Val R2: 0.7515\n",
      "No improvement in Val Loss for 1 epoch(s).\n",
      "Epoch 3/20, Train Loss: 0.0005, Val Loss: 0.0003, Train MAE: 0.0105, Val MAE: 0.0082, Train R2: 0.7456, Val R2: 0.8286\n",
      "Epoch 4/20, Train Loss: 0.0005, Val Loss: 0.0004, Train MAE: 0.0101, Val MAE: 0.0084, Train R2: 0.7606, Val R2: 0.7828\n",
      "No improvement in Val Loss for 1 epoch(s).\n",
      "Epoch 5/20, Train Loss: 0.0005, Val Loss: 0.0004, Train MAE: 0.0098, Val MAE: 0.0101, Train R2: 0.7699, Val R2: 0.7817\n",
      "No improvement in Val Loss for 2 epoch(s).\n",
      "Epoch 6/20, Train Loss: 0.0005, Val Loss: 0.0004, Train MAE: 0.0097, Val MAE: 0.0084, Train R2: 0.7719, Val R2: 0.7976\n",
      "No improvement in Val Loss for 3 epoch(s).\n",
      "Epoch 7/20, Train Loss: 0.0004, Val Loss: 0.0005, Train MAE: 0.0089, Val MAE: 0.0083, Train R2: 0.7904, Val R2: 0.7609\n",
      "No improvement in Val Loss for 4 epoch(s).\n",
      "Epoch 8/20, Train Loss: 0.0004, Val Loss: 0.0004, Train MAE: 0.0089, Val MAE: 0.0082, Train R2: 0.7941, Val R2: 0.7675\n",
      "No improvement in Val Loss for 5 epoch(s).\n",
      "Early stopping after 8 epochs...\n",
      "Model saved as model.pth\n"
     ]
    }
   ],
   "source": [
    "# Huấn luyện\n",
    "train_model(model, train_loader, val_loader, num_epochs=20, device=device)\n",
    "print(\"Model saved as model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
