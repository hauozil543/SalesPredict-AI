{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a66c345b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang sử dụng thiết bị: cuda\n",
      "Data loaded from SQLite successfully!\n",
      "Data shape: (304920, 15)\n",
      "Checking for NaN in features...\n",
      "item_id               0\n",
      "store_id              0\n",
      "date                  0\n",
      "sales                 0\n",
      "sell_price            0\n",
      "day_of_week           0\n",
      "snap_CA               0\n",
      "is_holiday            0\n",
      "month                 0\n",
      "day_of_month          0\n",
      "sales_lag_7           0\n",
      "sales_lag_14          0\n",
      "sales_lag_28          0\n",
      "sales_roll_mean_7     0\n",
      "sales_roll_mean_14    0\n",
      "dtype: int64\n",
      "Scaler feature names: ['sales' 'sell_price' 'day_of_week' 'snap_CA' 'is_holiday' 'month'\n",
      " 'day_of_month' 'sales_lag_7' 'sales_lag_14' 'sales_lag_28'\n",
      " 'sales_roll_mean_7' 'sales_roll_mean_14']\n",
      "Scaler data_min: [0.         0.09997559 0.         0.         0.         1.\n",
      " 1.         0.         0.         0.         0.         0.        ]\n",
      "Scaler data_max: [763.           4.98046875   6.           1.           1.\n",
      "  12.          31.         763.         763.         763.\n",
      " 602.85714286 468.64285714]\n",
      "Scaler scale (computed): [763.           4.88049316   6.           1.           1.\n",
      "  11.          30.         763.         763.         763.\n",
      " 602.85714286 468.64285714]\n",
      "\n",
      "Các case tham số có sẵn:\n",
      "Case 1: {'sequence_length': 28, 'batch_size': 32, 'num_epochs': 20, 'patience': 5, 'dropout': 0.3, 'hidden_size': 128}\n",
      "Case 2: {'sequence_length': 56, 'batch_size': 32, 'num_epochs': 20, 'patience': 5, 'dropout': 0.3, 'hidden_size': 128}\n",
      "Case 3: {'sequence_length': 56, 'batch_size': 32, 'num_epochs': 30, 'patience': 5, 'dropout': 0.3, 'hidden_size': 128}\n",
      "Case 4: {'sequence_length': 28, 'batch_size': 32, 'num_epochs': 30, 'patience': 3, 'dropout': 0.2, 'hidden_size': 128}\n",
      "Case 5: {'sequence_length': 28, 'batch_size': 32, 'num_epochs': 30, 'patience': 5, 'dropout': 0.1, 'hidden_size': 128}\n",
      "Nhập '0' để tự định nghĩa case mới.\n",
      "Đang chạy với tham số: {'sequence_length': 56, 'batch_size': 32, 'num_epochs': 20, 'patience': 5, 'dropout': 0.3, 'hidden_size': 128}\n",
      "Tên mô hình: lstm_model_2\n",
      "y trước chuẩn hóa (một số mẫu): [0.         0.0078637  0.         0.00262123 0.        ]\n",
      "y sau chuẩn hóa (một số mẫu): [1.71771427e-06 1.03062856e-05 1.71771427e-06 0.00000000e+00\n",
      " 1.20239999e-05]\n",
      "Total samples created: X=290808, y=290808, info=290808\n",
      "Train samples: X_train=203565, y_train=203565\n",
      "Validation samples: X_val=87243, y_val=87243, info_val=87243\n",
      "LSTM data prepared successfully!\n",
      "X_train shape: (203565, 56, 12)\n",
      "X_val shape: (87243, 56, 12)\n",
      "Length of info_val: 87243\n",
      "Kiểm tra dữ liệu trước khi huấn luyện...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ho Hau\\Downloads\\M5\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1329: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\c10/cuda/CUDAAllocatorConfig.h:28.)\n",
      "  return t.to(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to run torchinfo. See above stack traces for more details. Executed layers up to: []",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ho Hau\\Downloads\\M5\\venv\\Lib\\site-packages\\torchinfo\\torchinfo.py:295\u001b[39m, in \u001b[36mforward_pass\u001b[39m\u001b[34m(model, x, batch_dim, cache_forward_pass, device, mode, **kwargs)\u001b[39m\n\u001b[32m    294\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[32m--> \u001b[39m\u001b[32m295\u001b[39m     _ = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ho Hau\\Downloads\\M5\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ho Hau\\Downloads\\M5\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1845\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1844\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1845\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1846\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1847\u001b[39m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[32m   1848\u001b[39m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[32m   1849\u001b[39m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ho Hau\\Downloads\\M5\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1793\u001b[39m, in \u001b[36mModule._call_impl.<locals>.inner\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   1791\u001b[39m     args = bw_hook.setup_input_hook(args)\n\u001b[32m-> \u001b[39m\u001b[32m1793\u001b[39m result = \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1794\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 126\u001b[39m, in \u001b[36mLSTMModel.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    125\u001b[39m c0 = torch.zeros(\u001b[38;5;28mself\u001b[39m.num_layers, x.size(\u001b[32m0\u001b[39m), \u001b[38;5;28mself\u001b[39m.hidden_size).to(x.device)\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m out, _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mh0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc0\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    127\u001b[39m out = \u001b[38;5;28mself\u001b[39m.dropout(out[:, -\u001b[32m1\u001b[39m, :])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ho Hau\\Downloads\\M5\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ho Hau\\Downloads\\M5\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1845\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1844\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1845\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1846\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1847\u001b[39m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[32m   1848\u001b[39m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[32m   1849\u001b[39m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ho Hau\\Downloads\\M5\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1793\u001b[39m, in \u001b[36mModule._call_impl.<locals>.inner\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   1791\u001b[39m     args = bw_hook.setup_input_hook(args)\n\u001b[32m-> \u001b[39m\u001b[32m1793\u001b[39m result = \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1794\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ho Hau\\Downloads\\M5\\venv\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:1116\u001b[39m, in \u001b[36mLSTM.forward\u001b[39m\u001b[34m(self, input, hx)\u001b[39m\n\u001b[32m   1112\u001b[39m     msg = (\n\u001b[32m   1113\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFor unbatched 2-D input, hx and cx should \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1114\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33malso be 2-D but got (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhx[\u001b[32m0\u001b[39m].dim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m-D, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhx[\u001b[32m1\u001b[39m].dim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m-D) tensors\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1115\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1116\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg)\n\u001b[32m   1117\u001b[39m hx = (hx[\u001b[32m0\u001b[39m].unsqueeze(\u001b[32m1\u001b[39m), hx[\u001b[32m1\u001b[39m].unsqueeze(\u001b[32m1\u001b[39m))\n",
      "\u001b[31mRuntimeError\u001b[39m: For unbatched 2-D input, hx and cx should also be 2-D but got (3-D, 3-D) tensors",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 297\u001b[39m\n\u001b[32m    294\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m y_pred_orig, rmse_orig, mae_orig, wrmsse\n\u001b[32m    296\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m297\u001b[39m     results = \u001b[43mmain_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    298\u001b[39m     \u001b[38;5;66;03m# Gán các biến để sử dụng trong cell vẽ biểu đồ\u001b[39;00m\n\u001b[32m    299\u001b[39m     model = results[\u001b[33m'\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 199\u001b[39m, in \u001b[36mmain_train\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    192\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDữ liệu validation không đồng bộ: X_val=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(X_val)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, y_val=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(y_val)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, info_val=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(info_val)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    194\u001b[39m model = LSTMModel(\n\u001b[32m    195\u001b[39m     input_size=\u001b[38;5;28mlen\u001b[39m(features),\n\u001b[32m    196\u001b[39m     hidden_size=params[\u001b[33m'\u001b[39m\u001b[33mhidden_size\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m    197\u001b[39m     dropout=params[\u001b[33m'\u001b[39m\u001b[33mdropout\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m    198\u001b[39m ).to(device)\n\u001b[32m--> \u001b[39m\u001b[32m199\u001b[39m \u001b[43mprint_model_summary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msequence_length\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    201\u001b[39m model, metrics = train_model(model, train_loader, val_loader, params[\u001b[33m'\u001b[39m\u001b[33mnum_epochs\u001b[39m\u001b[33m'\u001b[39m], params[\u001b[33m'\u001b[39m\u001b[33mpatience\u001b[39m\u001b[33m'\u001b[39m], scaler, case_name)\n\u001b[32m    203\u001b[39m y_pred, rmse, mae, wrmsse = evaluate_model(model, X_val, y_val, info_val, scaler, params[\u001b[33m'\u001b[39m\u001b[33mbatch_size\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 134\u001b[39m, in \u001b[36mprint_model_summary\u001b[39m\u001b[34m(model, input_size)\u001b[39m\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprint_model_summary\u001b[39m(model, input_size):\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     \u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ho Hau\\Downloads\\M5\\venv\\Lib\\site-packages\\torchinfo\\torchinfo.py:223\u001b[39m, in \u001b[36msummary\u001b[39m\u001b[34m(model, input_size, input_data, batch_dim, cache_forward_pass, col_names, col_width, depth, device, dtypes, mode, row_settings, verbose, **kwargs)\u001b[39m\n\u001b[32m    216\u001b[39m validate_user_params(\n\u001b[32m    217\u001b[39m     input_data, input_size, columns, col_width, device, dtypes, verbose\n\u001b[32m    218\u001b[39m )\n\u001b[32m    220\u001b[39m x, correct_input_size = process_input(\n\u001b[32m    221\u001b[39m     input_data, input_size, batch_dim, device, dtypes\n\u001b[32m    222\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m223\u001b[39m summary_list = \u001b[43mforward_pass\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_forward_pass\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    225\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    226\u001b[39m formatting = FormattingOptions(depth, verbose, columns, col_width, rows)\n\u001b[32m    227\u001b[39m results = ModelStatistics(\n\u001b[32m    228\u001b[39m     summary_list, correct_input_size, get_total_memory_used(x), formatting\n\u001b[32m    229\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ho Hau\\Downloads\\M5\\venv\\Lib\\site-packages\\torchinfo\\torchinfo.py:304\u001b[39m, in \u001b[36mforward_pass\u001b[39m\u001b[34m(model, x, batch_dim, cache_forward_pass, device, mode, **kwargs)\u001b[39m\n\u001b[32m    302\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    303\u001b[39m     executed_layers = [layer \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m summary_list \u001b[38;5;28;01mif\u001b[39;00m layer.executed]\n\u001b[32m--> \u001b[39m\u001b[32m304\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    305\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFailed to run torchinfo. See above stack traces for more details. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    306\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExecuted layers up to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexecuted_layers\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    307\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    308\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    309\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m hooks:\n",
      "\u001b[31mRuntimeError\u001b[39m: Failed to run torchinfo. See above stack traces for more details. Executed layers up to: []"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import pickle\n",
    "import os\n",
    "from torchinfo import summary\n",
    "import time\n",
    "\n",
    "# Thiết lập môi trường\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Đang sử dụng thiết bị: {device}\")\n",
    "\n",
    "# Định nghĩa các case tham số\n",
    "cases = {\n",
    "    1: {'sequence_length': 28, 'batch_size': 32, 'num_epochs': 20, 'patience': 5, 'dropout': 0.3, 'hidden_size': 128},\n",
    "    2: {'sequence_length': 56, 'batch_size': 32, 'num_epochs': 20, 'patience': 5, 'dropout': 0.3, 'hidden_size': 128},\n",
    "    3: {'sequence_length': 56, 'batch_size': 32, 'num_epochs': 30, 'patience': 5, 'dropout': 0.3, 'hidden_size': 128},\n",
    "    4: {'sequence_length': 28, 'batch_size': 32, 'num_epochs': 30, 'patience': 3, 'dropout': 0.2, 'hidden_size': 128},\n",
    "    5: {'sequence_length': 28, 'batch_size': 32, 'num_epochs': 30, 'patience': 5, 'dropout': 0.1, 'hidden_size': 128},\n",
    "}\n",
    "\n",
    "# Bước 1: Tải dữ liệu từ SQLite\n",
    "def load_data_from_sqlite():\n",
    "    conn = sqlite3.connect('historical_data1.db')\n",
    "    query = \"SELECT * FROM historical_data1 ORDER BY item_id, store_id, date\"\n",
    "    data = pd.read_sql_query(query, conn)\n",
    "    conn.close()\n",
    "    data['date'] = pd.to_datetime(data['date'])\n",
    "    print(\"Data loaded from SQLite successfully!\")\n",
    "    print(f\"Data shape: {data.shape}\")\n",
    "    print(\"Checking for NaN in features...\")\n",
    "    print(data.isna().sum())\n",
    "    return data\n",
    "\n",
    "# Dataset và DataLoader\n",
    "class SalesDataset(Dataset):\n",
    "    def __init__(self, X, y, info=None):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "        self.info = info\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.info is not None:\n",
    "            return self.X[idx], self.y[idx], self.info[idx]\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "def prepare_lstm_data(data, features, sequence_length, batch_size):\n",
    "    X, y, info = [], [], []\n",
    "    unique_items = data[['item_id', 'store_id']].drop_duplicates().values\n",
    "    \n",
    "    with open('utils/scaler1.pkl', 'rb') as f:\n",
    "        scaler = pickle.load(f)\n",
    "    \n",
    "    valid_pairs = 0\n",
    "    for item_id, store_id in unique_items:\n",
    "        item_data = data[(data['item_id'] == item_id) & (data['store_id'] == store_id)].sort_values('date')\n",
    "        if len(item_data) < sequence_length + 1:\n",
    "            continue\n",
    "        valid_pairs += 1\n",
    "        item_features = item_data[features].values\n",
    "        item_dates = item_data['date'].astype(str).values\n",
    "        num_samples = len(item_data) - sequence_length\n",
    "        for i in range(num_samples):\n",
    "            X.append(item_features[i:i + sequence_length])\n",
    "            y_val = item_features[i + sequence_length, 0]  # Giá trị gốc của sales\n",
    "            # Chuẩn hóa y_val bằng scaler với DataFrame\n",
    "            df_to_scale = pd.DataFrame([[y_val] + [0] * (len(scaler.feature_names_in_) - 1)], columns=scaler.feature_names_in_)\n",
    "            y_scaled = scaler.transform(df_to_scale)[:, 0]\n",
    "            y.append(y_scaled)\n",
    "            info.append((item_id, store_id, item_dates[i + sequence_length]))\n",
    "    \n",
    "    X = np.array(X)\n",
    "    y = np.array(y).flatten()\n",
    "    info = np.array(info, dtype=object)\n",
    "    \n",
    "    print(f\"y trước chuẩn hóa (một số mẫu):\", item_features[:5, 0])  # Kiểm tra giá trị gốc\n",
    "    print(f\"y sau chuẩn hóa (một số mẫu):\", y[:5])  # Kiểm tra giá trị chuẩn hóa\n",
    "    \n",
    "    train_size = int(0.7 * len(X))\n",
    "    X_train, X_val = X[:train_size], X[train_size:]\n",
    "    y_train, y_val = y[:train_size], y[train_size:]\n",
    "    info_val = info[train_size:].tolist()\n",
    "    \n",
    "    print(f\"Total samples created: X={len(X)}, y={len(y)}, info={len(info)}\")\n",
    "    print(f\"Train samples: X_train={len(X_train)}, y_train={len(y_train)}\")\n",
    "    print(f\"Validation samples: X_val={len(X_val)}, y_val={len(y_val)}, info_val={len(info_val)}\")\n",
    "    if not (len(X_val) == len(y_val) == len(info_val)):\n",
    "        raise ValueError(f\"Mismatch in validation data: X_val={len(X_val)}, y_val={len(y_val)}, info_val={len(info_val)}\")\n",
    "    \n",
    "    train_dataset = SalesDataset(X_train, y_train)\n",
    "    val_dataset = SalesDataset(X_val, y_val, info_val)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    print(\"LSTM data prepared successfully!\")\n",
    "    print(f\"X_train shape: {X_train.shape}\")\n",
    "    print(f\"X_val shape: {X_val.shape}\")\n",
    "    print(f\"Length of info_val: {len(info_val)}\")\n",
    "    return train_loader, val_loader, X_val, y_val, info_val\n",
    "\n",
    "# Mô hình LSTM\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size=12, hidden_size=128, num_layers=3, dropout=0.3):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc1 = nn.Linear(hidden_size, 32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(32, 1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.dropout(out[:, -1, :])\n",
    "        out = self.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        out = torch.clamp(out, 0, 1)  # Giới hạn đầu ra trong [0, 1] để phù hợp với MinMaxScaler\n",
    "        return out\n",
    "\n",
    "def print_model_summary(model, input_size):\n",
    "    summary(model, input_size=input_size)\n",
    "\n",
    "# Hàm huấn luyện (giả sử bạn có hàm train_model, tôi sẽ để trống)\n",
    "def train_model(model, train_loader, val_loader, num_epochs, patience, scaler, case_name):\n",
    "    # Thêm code huấn luyện của bạn ở đây\n",
    "    pass\n",
    "\n",
    "# Hàm tính WRMSSE (giả sử bạn có hàm calculate_wrmsse)\n",
    "def calculate_wrmsse(val_df):\n",
    "    # Thêm code tính WRMSSE của bạn ở đây\n",
    "    return 0.8814  # Giá trị giả định\n",
    "\n",
    "# Hàm chính cho huấn luyện và đánh giá\n",
    "def main_train():\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    data = load_data_from_sqlite()\n",
    "    \n",
    "    with open('utils/scaler1.pkl', 'rb') as f:\n",
    "        scaler = pickle.load(f)\n",
    "    print(\"Scaler feature names:\", scaler.feature_names_in_)\n",
    "    print(\"Scaler data_min:\", scaler.data_min_)\n",
    "    print(\"Scaler data_max:\", scaler.data_max_)\n",
    "    print(\"Scaler scale (computed):\", scaler.data_max_ - scaler.data_min_)\n",
    "    \n",
    "    features = ['sales', 'sell_price', 'day_of_week', 'snap_CA', 'is_holiday', 'month', 'day_of_month',\n",
    "                'sales_lag_7', 'sales_lag_14', 'sales_lag_28', 'sales_roll_mean_7', 'sales_roll_mean_14']\n",
    "    \n",
    "    print(\"\\nCác case tham số có sẵn:\")\n",
    "    for case_num, params in cases.items():\n",
    "        print(f\"Case {case_num}: {params}\")\n",
    "    print(\"Nhập '0' để tự định nghĩa case mới.\")\n",
    "    \n",
    "    case_choice = int(input(\"Nhập số case (0-5): \"))\n",
    "    \n",
    "    if case_choice == 0:\n",
    "        params = {\n",
    "            'sequence_length': int(input(\"Nhập sequence_length: \")),\n",
    "            'batch_size': int(input(\"Nhập batch_size: \")),\n",
    "            'num_epochs': int(input(\"Nhập num_epochs: \")),\n",
    "            'patience': int(input(\"Nhập patience: \")),\n",
    "            'dropout': float(input(\"Nhập dropout (0.0-1.0): \")),\n",
    "            'hidden_size': int(input(\"Nhập hidden_size: \"))\n",
    "        }\n",
    "        case_name = f\"lstm_model_custom_{params['sequence_length']}_{params['batch_size']}_{params['hidden_size']}\"\n",
    "    else:\n",
    "        params = cases.get(case_choice, cases[1])\n",
    "        case_name = f\"lstm_model_{case_choice}\"\n",
    "    \n",
    "    print(f\"Đang chạy với tham số: {params}\")\n",
    "    print(f\"Tên mô hình: {case_name}\")\n",
    "    \n",
    "    train_loader, val_loader, X_val, y_val, info_val = prepare_lstm_data(\n",
    "        data, features, params['sequence_length'], params['batch_size']\n",
    "    )\n",
    "    \n",
    "    print(\"Kiểm tra dữ liệu trước khi huấn luyện...\")\n",
    "    if not (len(X_val) == len(y_val) == len(info_val)):\n",
    "        raise ValueError(f\"Dữ liệu validation không đồng bộ: X_val={len(X_val)}, y_val={len(y_val)}, info_val={len(info_val)}\")\n",
    "    \n",
    "    model = LSTMModel(\n",
    "        input_size=len(features),\n",
    "        hidden_size=params['hidden_size'],\n",
    "        dropout=params['dropout']\n",
    "    ).to(device)\n",
    "    print_model_summary(model, (params['sequence_length'], len(features)))\n",
    "    \n",
    "    model, metrics = train_model(model, train_loader, val_loader, params['num_epochs'], params['patience'], scaler, case_name)\n",
    "    \n",
    "    y_pred, rmse, mae, wrmsse = evaluate_model(model, X_val, y_val, info_val, scaler, params['batch_size'])\n",
    "    \n",
    "    print(\"\\nHuấn luyện và đánh giá hoàn tất!\")\n",
    "    \n",
    "    final_model_path = f\"{case_name}.pth\"\n",
    "    torch.save(model.state_dict(), final_model_path)\n",
    "    print(f\"Mô hình cuối cùng đã được lưu tại {final_model_path}\")\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'y_pred': y_pred,\n",
    "        'y_val': y_val,\n",
    "        'info_val': info_val,\n",
    "        'scaler': scaler,\n",
    "        'rmse': rmse,\n",
    "        'mae': mae,\n",
    "        'wrmsse': wrmsse,\n",
    "        'case_name': case_name\n",
    "    }\n",
    "\n",
    "def evaluate_model(model, X_val, y_val, info_val, scaler, batch_size):\n",
    "    model.eval()\n",
    "    dataset = SalesDataset(X_val, y_val, info_val)\n",
    "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    y_pred_list = []\n",
    "    y_true_list = []\n",
    "    info_list = []\n",
    "    current_idx = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch, _ in data_loader:\n",
    "            batch_size_actual = X_batch.shape[0]\n",
    "            X_batch = X_batch.to(device)\n",
    "            outputs = model(X_batch)\n",
    "            y_pred_batch = outputs.squeeze().cpu().numpy()\n",
    "            y_true_batch = y_batch.numpy()\n",
    "            batch_info = info_val[current_idx:current_idx + batch_size_actual]\n",
    "            y_pred_list.append(y_pred_batch)\n",
    "            y_true_list.append(y_true_batch)\n",
    "            info_list.extend(batch_info)\n",
    "            current_idx += batch_size_actual\n",
    "    \n",
    "    y_pred = np.concatenate(y_pred_list)\n",
    "    y_true = np.concatenate(y_true_list)\n",
    "    \n",
    "    print(\"Length of info_list:\", len(info_list))\n",
    "    print(\"Length of y_true:\", len(y_true))\n",
    "    print(\"Length of y_pred:\", len(y_pred))\n",
    "    \n",
    "    if not (len(info_list) == len(y_true) == len(y_pred)):\n",
    "        raise ValueError(f\"Mismatch in lengths: info_list={len(info_list)}, y_true={len(y_true)}, y_pred={len(y_pred)}\")\n",
    "    \n",
    "    print(\"y_true (chuẩn hóa):\", y_true[:10])\n",
    "    print(\"y_pred (chuẩn hóa):\", y_pred[:10])\n",
    "    \n",
    "    # Chuyển đổi ngược với MinMaxScaler sử dụng DataFrame\n",
    "    y_true_df = pd.DataFrame(np.zeros((len(y_true), len(scaler.feature_names_in_))), columns=scaler.feature_names_in_)\n",
    "    y_true_df['sales'] = y_true\n",
    "    y_pred_df = pd.DataFrame(np.zeros((len(y_pred), len(scaler.feature_names_in_))), columns=scaler.feature_names_in_)\n",
    "    y_pred_df['sales'] = y_pred\n",
    "    \n",
    "    y_true_orig = scaler.inverse_transform(y_true_df)[:, 0]\n",
    "    y_pred_orig = scaler.inverse_transform(y_pred_df)[:, 0]\n",
    "    \n",
    "    print(\"y_true_orig (sau inverse):\", y_true_orig[:10])\n",
    "    print(\"y_pred_orig (sau inverse):\", y_pred_orig[:10])\n",
    "    \n",
    "    rmse_scaled = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae_scaled = mean_absolute_error(y_true, y_pred)\n",
    "    \n",
    "    rmse_orig = np.sqrt(mean_squared_error(y_true_orig, y_pred_orig))\n",
    "    mae_orig = mean_absolute_error(y_true_orig, y_pred_orig)\n",
    "    \n",
    "    val_df = pd.DataFrame({\n",
    "        'item_id': [info[0] for info in info_list],\n",
    "        'store_id': [info[1] for info in info_list],\n",
    "        'date': [info[2] for info in info_list],\n",
    "        'actual': y_true_orig,\n",
    "        'predicted': y_pred_orig\n",
    "    })\n",
    "    wrmsse = calculate_wrmsse(val_df)\n",
    "    \n",
    "    print(\"\\nChỉ số trên dữ liệu chuẩn hóa:\")\n",
    "    print(f\"RMSE (chuẩn hóa): {rmse_scaled:.6f}\")\n",
    "    print(f\"MAE (chuẩn hóa): {mae_scaled:.6f}\")\n",
    "    print(\"\\nChỉ số trên dữ liệu gốc:\")\n",
    "    print(f\"RMSE (gốc): {rmse_orig:.4f}\")\n",
    "    print(f\"MAE (gốc): {mae_orig:.4f}\")\n",
    "    print(f\"WRMSSE: {wrmsse:.4f}\")\n",
    "    \n",
    "    return y_pred_orig, rmse_orig, mae_orig, wrmsse\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    results = main_train()\n",
    "    # Gán các biến để sử dụng trong cell vẽ biểu đồ\n",
    "    model = results['model']\n",
    "    y_pred = results['y_pred']\n",
    "    y_val = results['y_val']\n",
    "    info_val = results['info_val']\n",
    "    scaler = results['scaler']\n",
    "    rmse = results['rmse']\n",
    "    mae = results['mae']\n",
    "    wrmsse = results['wrmsse']\n",
    "    case_name = results['case_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1853ca40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Hàm để vẽ biểu đồ so sánh dữ liệu thực tế và dự đoán\n",
    "def plot_actual_vs_predicted(y_true, y_pred, info_val, scaler, rmse, mae, wrmsse, case_name, num_samples=100, item_id=None, store_id=None):\n",
    "    \"\"\"\n",
    "    Vẽ biểu đồ so sánh dữ liệu thực tế và dự đoán trên tập validation.\n",
    "    \n",
    "    Parameters:\n",
    "    - y_true: Giá trị thực tế (chuẩn hóa) từ tập validation.\n",
    "    - y_pred: Giá trị dự đoán (chuẩn hóa) từ mô hình.\n",
    "    - info_val: Thông tin về item_id, store_id, và date cho tập validation.\n",
    "    - scaler: Scaler để chuyển đổi ngược về giá trị gốc.\n",
    "    - rmse: RMSE trên giá trị gốc.\n",
    "    - mae: MAE trên giá trị gốc.\n",
    "    - wrmsse: WRMSSE trên giá trị gốc.\n",
    "    - case_name: Tên case để hiển thị trong tiêu đề và lưu file.\n",
    "    - num_samples: Số mẫu tối đa để vẽ (mặc định: 100).\n",
    "    - item_id: Nếu được cung cấp, chỉ vẽ cho item_id cụ thể.\n",
    "    - store_id: Nếu được cung cấp, chỉ vẽ cho store_id cụ thể.\n",
    "    \"\"\"\n",
    "    # Chuyển đổi ngược với MinMaxScaler sử dụng DataFrame\n",
    "    y_true_df = pd.DataFrame(np.zeros((len(y_true), len(scaler.feature_names_in_))), columns=scaler.feature_names_in_)\n",
    "    y_true_df['sales'] = y_true\n",
    "    y_pred_df = pd.DataFrame(np.zeros((len(y_pred), len(scaler.feature_names_in_))), columns=scaler.feature_names_in_)\n",
    "    y_pred_df['sales'] = y_pred\n",
    "    \n",
    "    y_true_orig = scaler.inverse_transform(y_true_df)[:, 0]\n",
    "    y_pred_orig = scaler.inverse_transform(y_pred_df)[:, 0]\n",
    "    \n",
    "    # Kiểm tra NaN hoặc inf\n",
    "    if np.any(np.isnan(y_true_orig)) or np.any(np.isnan(y_pred_orig)) or np.any(np.isinf(y_true_orig)) or np.any(np.isinf(y_pred_orig)):\n",
    "        print(\"Cảnh báo: Dữ liệu chứa NaN hoặc inf sau khi chuyển đổi ngược!\")\n",
    "        return\n",
    "    \n",
    "    # Tạo DataFrame từ info_val để dễ lọc\n",
    "    val_df = pd.DataFrame({\n",
    "        'item_id': [info[0] for info in info_val],\n",
    "        'store_id': [info[1] for info in info_val],\n",
    "        'date': [info[2] for info in info_val],\n",
    "        'actual': y_true_orig,\n",
    "        'predicted': y_pred_orig\n",
    "    })\n",
    "    \n",
    "    # Lọc theo item_id và store_id nếu được cung cấp\n",
    "    if item_id is not None and store_id is not None:\n",
    "        val_df = val_df[(val_df['item_id'] == item_id) & (val_df['store_id'] == store_id)]\n",
    "        if val_df.empty:\n",
    "            print(f\"Không có dữ liệu cho item_id={item_id} và store_id={store_id} trong tập validation.\")\n",
    "            return\n",
    "        title = f'So sánh thực tế vs dự đoán cho Item {item_id}, Store {store_id} (Case {case_name})'\n",
    "    else:\n",
    "        # Lấy một số mẫu đầu tiên nếu không lọc\n",
    "        val_df = val_df.iloc[:min(num_samples, len(val_df))]\n",
    "        title = f'So sánh thực tế vs dự đoán trên {len(val_df)} mẫu đầu tiên (Case {case_name})'\n",
    "    \n",
    "    # Sắp xếp theo date để vẽ theo thứ tự thời gian\n",
    "    val_df['date'] = pd.to_datetime(val_df['date'], utc=True, errors='coerce')\n",
    "    val_df = val_df.sort_values('date')\n",
    "    \n",
    "    # Loại bỏ NaN nếu có sau khi chuyển đổi datetime\n",
    "    val_df = val_df.dropna()\n",
    "    \n",
    "    # Vẽ biểu đồ\n",
    "    plt.figure(figsize=(14, 8))  # Tăng kích thước biểu đồ\n",
    "    plt.plot(val_df['date'], val_df['actual'], label='Thực tế', color='blue', marker='o', linestyle='-')\n",
    "    plt.plot(val_df['date'], val_df['predicted'], label='Dự đoán', color='red', marker='x', linestyle='--')\n",
    "    \n",
    "    # Thêm tiêu đề và nhãn\n",
    "    plt.title(f'{title}\\nRMSE: {rmse:.4f}, MAE: {mae:.4f}, WRMSSE: {wrmsse:.4f}', fontsize=10)\n",
    "    plt.xlabel('Ngày', fontsize=10)\n",
    "    plt.ylabel('Doanh số (giá trị gốc)', fontsize=10)\n",
    "    plt.legend(fontsize=10)\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Xoay nhãn ngày để dễ đọc\n",
    "    plt.xticks(rotation=45, fontsize=8)\n",
    "    \n",
    "    # Điều chỉnh layout để tránh cắt nhãn\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Lưu biểu đồ\n",
    "    plt.savefig(f'actual_vs_predicted_{case_name}.png', dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    # Hiển thị biểu đồ\n",
    "    plt.show()\n",
    "\n",
    "# Kiểm tra các item_id và store_id trong tập validation\n",
    "unique_items = set((info[0], info[1]) for info in info_val)\n",
    "print(\"Các cặp item_id, store_id trong tập validation:\", unique_items)\n",
    "\n",
    "# Vẽ biểu đồ cho HOUSEHOLD_1465, CA_2\n",
    "plot_actual_vs_predicted(y_val, y_pred, info_val, scaler, rmse, mae, wrmsse, case_name, item_id='HOUSEHOLD_1465', store_id='CA_2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
