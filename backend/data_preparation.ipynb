{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "345950bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import tất cả các thư viện cần thiết\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4f2d8ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Định nghĩa hàm reduce_mem_usage\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics: \n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c7c4f95f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 130.48 Mb (37.5% reduction)\n",
      "Sell prices has 6841121 rows and 4 columns\n",
      "Mem. usage decreased to  0.12 Mb (41.9% reduction)\n",
      "Calendar has 1969 rows and 14 columns\n",
      "Mem. usage decreased to 95.00 Mb (78.7% reduction)\n",
      "Sales train validation has 30490 rows and 1919 columns\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Đọc dữ liệu\n",
    "def read_data():\n",
    "    INPUT_DIR_PATH = 'C:/Users/Ho Hau/Downloads/M5/data/raw/'\n",
    "    sell_prices_df = pd.read_csv(INPUT_DIR_PATH + 'sell_prices.csv')\n",
    "    sell_prices_df = reduce_mem_usage(sell_prices_df)\n",
    "    print('Sell prices has {} rows and {} columns'.format(sell_prices_df.shape[0], sell_prices_df.shape[1]))\n",
    "    \n",
    "    calendar_df = pd.read_csv(INPUT_DIR_PATH + 'calendar.csv')\n",
    "    calendar_df = reduce_mem_usage(calendar_df)\n",
    "    print('Calendar has {} rows and {} columns'.format(calendar_df.shape[0], calendar_df.shape[1]))\n",
    "    \n",
    "    sales_train_validation_df = pd.read_csv(INPUT_DIR_PATH + 'sales_train_validation.csv')\n",
    "    sales_train_validation_df = reduce_mem_usage(sales_train_validation_df)\n",
    "    print('Sales train validation has {} rows and {} columns'.format(sales_train_validation_df.shape[0], sales_train_validation_df.shape[1]))\n",
    "    \n",
    "    return sell_prices_df, calendar_df, sales_train_validation_df\n",
    "\n",
    "sell_prices_df, calendar_df, sales_train_validation_df = read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0c83cd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Lọc top 10 sản phẩm bán chạy nhất (đã sửa lỗi)\n",
    "d_cols = [c for c in sales_train_validation_df.columns if c.startswith('d_')]\n",
    "sum_series = sales_train_validation_df.copy()\n",
    "sum_series['total'] = sum_series[d_cols].sum(axis=1)\n",
    "top_k = 10\n",
    "top_series = sum_series.nlargest(top_k, 'total')[['item_id', 'store_id']]\n",
    "sales_long = (\n",
    "    sales_train_validation_df.merge(top_series, on=['item_id', 'store_id'], how='inner')\n",
    "    .melt(id_vars=['item_id', 'store_id'], value_vars=d_cols,\n",
    "          var_name='d', value_name='sales')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d3598ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Kết hợp dữ liệu\n",
    "df = sales_long.merge(calendar_df, on='d', how='left')\n",
    "df = df.merge(sell_prices_df, on=['store_id', 'item_id', 'wm_yr_wk'], how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4ef9c36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Xử lý đặc trưng\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['day'] = df['date'].dt.day\n",
    "df['month'] = df['date'].dt.month\n",
    "df['weekday'] = df['date'].dt.weekday\n",
    "try:\n",
    "    df['week'] = df['date'].dt.isocalendar().week\n",
    "except:\n",
    "    df['week'] = df['date'].dt.week\n",
    "\n",
    "df['event'] = df['event_name_1'].fillna('None')\n",
    "df = pd.get_dummies(df, columns=['event'], prefix='evt')\n",
    "for col in ['snap_CA', 'snap_TX', 'snap_WI']:\n",
    "    df[col] = df[col].fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8a3b98a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thêm lag và rolling mean\n",
    "for lag in [7, 14, 28]:\n",
    "    df[f'sales_lag_{lag}'] = df.groupby(['item_id', 'store_id'])['sales'].shift(lag)\n",
    "df['rolling_mean_7'] = (\n",
    "    df.groupby(['item_id', 'store_id'])['sales']\n",
    "      .transform(lambda x: x.shift(1).rolling(7).mean())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a411ac88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xử lý NaN\n",
    "df = df.fillna({'sell_price': 0, 'sales': 0, 'sales_lag_7': 0, 'sales_lag_14': 0, 'sales_lag_28': 0, 'rolling_mean_7': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "57eb847a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler saved to 'utils/scaler.pkl'\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Chuẩn hóa dữ liệu và mã hóa item/store\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Đảm bảo thư mục utils/ tồn tại\n",
    "if not os.path.exists('utils'):\n",
    "    os.makedirs('utils')\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "numeric_cols = ['sell_price', 'sales', 'sales_lag_7', 'sales_lag_14', 'sales_lag_28', 'rolling_mean_7']\n",
    "df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
    "\n",
    "# Lưu scaler vào utils/scaler.pkl\n",
    "with open('utils/scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "print(\"Scaler saved to 'utils/scaler.pkl'\")\n",
    "\n",
    "item_enc = LabelEncoder().fit(df['item_id'])\n",
    "store_enc = LabelEncoder().fit(df['store_id'])\n",
    "df['item_idx'] = item_enc.transform(df['item_id'])\n",
    "df['store_idx'] = store_enc.transform(df['store_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6216e017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to processed_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Lưu dữ liệu đã xử lý\n",
    "df.to_csv('processed_data.csv', index=False)\n",
    "print('Processed data saved to processed_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
