{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "345950bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import tất cả các thư viện cần thiết\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "import warnings\n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f2d8ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Định nghĩa hàm reduce_mem_usage\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics: \n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7c4f95f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 130.48 Mb (37.5% reduction)\n",
      "Sell prices has 6841121 rows and 4 columns\n",
      "Mem. usage decreased to  0.12 Mb (41.9% reduction)\n",
      "Calendar has 1969 rows and 14 columns\n",
      "Mem. usage decreased to 95.00 Mb (78.7% reduction)\n",
      "Sales train validation has 30490 rows and 1919 columns\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Đọc dữ liệu\n",
    "def read_data():\n",
    "    INPUT_DIR_PATH = 'C:/Users/Ho Hau/Downloads/M5/data/raw/'\n",
    "    sell_prices_df = pd.read_csv(INPUT_DIR_PATH + 'sell_prices.csv')\n",
    "    sell_prices_df = reduce_mem_usage(sell_prices_df)\n",
    "    print('Sell prices has {} rows and {} columns'.format(sell_prices_df.shape[0], sell_prices_df.shape[1]))\n",
    "    \n",
    "    calendar_df = pd.read_csv(INPUT_DIR_PATH + 'calendar.csv')\n",
    "    calendar_df = reduce_mem_usage(calendar_df)\n",
    "    print('Calendar has {} rows and {} columns'.format(calendar_df.shape[0], calendar_df.shape[1]))\n",
    "    \n",
    "    sales_train_validation_df = pd.read_csv(INPUT_DIR_PATH + 'sales_train_validation.csv')\n",
    "    sales_train_validation_df = reduce_mem_usage(sales_train_validation_df)\n",
    "    print('Sales train validation has {} rows and {} columns'.format(sales_train_validation_df.shape[0], sales_train_validation_df.shape[1]))\n",
    "    \n",
    "    return sell_prices_df, calendar_df, sales_train_validation_df\n",
    "\n",
    "sell_prices_df, calendar_df, sales_train_validation_df = read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7177869c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in calendar_df: ['date', 'wm_yr_wk', 'weekday', 'wday', 'month', 'year', 'd', 'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2', 'snap_CA', 'snap_TX', 'snap_WI']\n"
     ]
    }
   ],
   "source": [
    "# Kiểm tra các cột trong calendar_df\n",
    "print(\"Columns in calendar_df:\", calendar_df.columns.tolist())\n",
    "if 'date' not in calendar_df.columns:\n",
    "    raise KeyError(\"Column 'date' not found in calendar_df. Please check the data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9987486f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Chuyển dữ liệu sang dạng long\n",
    "d_cols = [c for c in sales_train_validation_df.columns if c.startswith('d_')]\n",
    "d_cols = d_cols[-360:]  # Lấy 360 ngày cuối\n",
    "sales_long = sales_train_validation_df.melt(id_vars=['item_id', 'store_id'], value_vars=d_cols, var_name='d', value_name='sales')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0dbd67f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in sales_long after merging with calendar_df: ['item_id', 'store_id', 'd', 'sales', 'date', 'wm_yr_wk', 'event_name_1', 'event_name_2', 'snap_CA', 'snap_TX', 'snap_WI']\n"
     ]
    }
   ],
   "source": [
    "# Gộp với calendar_df để lấy các cột thời gian và sự kiện\n",
    "calendar_df['date'] = pd.to_datetime(calendar_df['date'])\n",
    "sales_long = sales_long.merge(calendar_df[['d', 'date', 'wm_yr_wk', 'event_name_1', 'event_name_2', 'snap_CA', 'snap_TX', 'snap_WI']], on='d')\n",
    "# Kiểm tra các cột trong sales_long sau khi merge với calendar_df\n",
    "print(\"Columns in sales_long after merging with calendar_df:\", sales_long.columns.tolist())\n",
    "if 'date' not in sales_long.columns:\n",
    "    raise KeyError(\"Column 'date' not found in sales_long after merging with calendar_df.\")\n",
    "# Gộp với sell_prices_df thông qua wm_yr_wk\n",
    "sales_long = sales_long.merge(sell_prices_df, on=['store_id', 'item_id', 'wm_yr_wk'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e16845d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm chọn mã đại diện\n",
    "def select_representative_items(df, stores, categories=['FOODS', 'HOUSEHOLD']):\n",
    "    selected_items = []\n",
    "    for store in stores:\n",
    "        for category in categories:\n",
    "            # Lọc dữ liệu của cửa hàng và danh mục\n",
    "            df_store = df[df['store_id'] == store]\n",
    "            df_store = df_store[df_store['item_id'].str.startswith(category)]\n",
    "            \n",
    "            # Tính tổng doanh số cho mỗi sản phẩm\n",
    "            item_sales = df_store.groupby('item_id')['sales'].sum().reset_index()\n",
    "            \n",
    "            if not item_sales.empty:\n",
    "                # Sắp xếp theo doanh số\n",
    "                item_sales = item_sales.sort_values('sales')\n",
    "                # Chọn sản phẩm có doanh số thấp nhất\n",
    "                if len(item_sales) > 0:\n",
    "                    selected_items.append(item_sales.iloc[0]['item_id'])\n",
    "                # Chọn sản phẩm có doanh số trung bình (gần trung vị)\n",
    "                if len(item_sales) > 1:\n",
    "                    median_sales = item_sales['sales'].median()\n",
    "                    closest_item = item_sales.iloc[(item_sales['sales'] - median_sales).abs().argmin()]\n",
    "                    selected_items.append(closest_item['item_id'])\n",
    "                # Chọn sản phẩm có doanh số cao nhất\n",
    "                if len(item_sales) > 2:\n",
    "                    selected_items.append(item_sales.iloc[-1]['item_id'])\n",
    "    \n",
    "    # Lọc dữ liệu chỉ giữ các sản phẩm đại diện\n",
    "    return df[df['item_id'].isin(selected_items)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8040436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chọn mã đại diện cho tất cả các cửa hàng\n",
    "all_stores = ['CA_1', 'CA_2', 'CA_3', 'CA_4', 'TX_1', 'TX_2', 'TX_3', 'WI_1', 'WI_2', 'WI_3']\n",
    "df = select_representative_items(sales_long, all_stores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9b85ea91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Hàm tạo đặc trưng\n",
    "def add_features(df):\n",
    "    # Đảm bảo cột date tồn tại và ở định dạng datetime\n",
    "    if 'date' not in df.columns:\n",
    "        raise KeyError(\"Column 'date' not found in df before applying add_features.\")\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['day'] = df['date'].dt.day\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['weekday'] = df['date'].dt.weekday\n",
    "    df['week'] = df['date'].dt.isocalendar().week\n",
    "\n",
    "    # Chuẩn hóa sự kiện và SNAP\n",
    "    df['event'] = ((df['event_name_1'].notnull()) | (df['event_name_2'].notnull())).astype(int)\n",
    "    df['snap'] = df.apply(lambda x: 1 if (x['store_id'].startswith('CA') and x['snap_CA'] == 1) or \n",
    "                                        (x['store_id'].startswith('TX') and x['snap_TX'] == 1) or \n",
    "                                        (x['store_id'].startswith('WI') and x['snap_WI'] == 1) else 0, axis=1)\n",
    "\n",
    "    # Đặc trưng chu kỳ\n",
    "    df['weekday_sin'] = np.sin(2 * np.pi * df['weekday'] / 7)\n",
    "    df['weekday_cos'] = np.cos(2 * np.pi * df['weekday'] / 7)\n",
    "    df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
    "    df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
    "\n",
    "    # Lag và rolling mean\n",
    "    for lag in [7, 14, 28]:\n",
    "        df[f'sales_lag_{lag}'] = df.groupby(['item_id', 'store_id'])['sales'].shift(lag)\n",
    "    df['rolling_mean_7'] = df.groupby(['item_id', 'store_id'])['sales'].transform(lambda x: x.shift(1).rolling(7).mean())\n",
    "    df['rolling_mean_14'] = df.groupby(['item_id', 'store_id'])['sales'].transform(lambda x: x.shift(1).rolling(14).mean())\n",
    "\n",
    "    # Điền NaN\n",
    "    df.fillna({'sell_price': 0, 'sales': 0, 'sales_lag_7': 0, 'sales_lag_14': 0, 'sales_lag_28': 0, 'rolling_mean_7': 0, 'rolling_mean_14': 0}, inplace=True)\n",
    "\n",
    "    # Chuẩn hóa đặc trưng số\n",
    "    scaler = MinMaxScaler()\n",
    "    numeric_cols = ['sales', 'sell_price', 'sales_lag_7', 'sales_lag_14', 'sales_lag_28', 'rolling_mean_7', 'rolling_mean_14']\n",
    "    df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
    "    with open('utils/scaler.pkl', 'wb') as f:\n",
    "        pickle.dump(scaler, f)\n",
    "    # Mã hóa lại item_id và store_id SAU KHI lọc dữ liệu\n",
    "    item_enc = LabelEncoder()\n",
    "    store_enc = LabelEncoder()\n",
    "    df['item_idx'] = item_enc.fit_transform(df['item_id'])\n",
    "    df['store_idx'] = store_enc.fit_transform(df['store_id'])\n",
    "\n",
    "    return df, item_enc, store_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cdb1efca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Áp dụng cho dữ liệu gộp\n",
    "df, item_enc, store_enc = add_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "236b88ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lưu dữ liệu vào SQLite\n",
    "conn = sqlite3.connect('processed_data.db')\n",
    "df.drop(['item_id', 'store_id', 'event_name_1', 'event_name_2', 'snap_CA', 'snap_TX', 'snap_WI', 'weekday', 'month'], axis=1, inplace=True)\n",
    "df.to_sql('data', conn, if_exists='replace', index=False)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cbafa486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lưu bộ mã hóa\n",
    "import pickle\n",
    "with open('utils/item_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump({item: idx for idx, item in enumerate(item_enc.classes_)}, f)\n",
    "with open('utils/store_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump({store: idx for idx, store in enumerate(store_enc.classes_)}, f)\n",
    "\n",
    "# Lưu thông tin đặc trưng\n",
    "feature_cols = ['day', 'weekday_sin', 'weekday_cos', 'month_sin', 'month_cos', 'week',\n",
    "                'sales_lag_7', 'sales_lag_14','sales_lag_28', 'rolling_mean_7','rolling_mean_7', 'sell_price', 'event', 'snap']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a7358921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kiểm tra item_enc và store_enc\n",
    "if 'item_enc' not in globals() or 'store_enc' not in globals():\n",
    "    raise NameError(\"item_enc or store_enc is not defined. Ensure add_features() returned these variables correctly.\")\n",
    "\n",
    "try:\n",
    "    with open('model_params.txt', 'w') as f:\n",
    "        f.write(f\"num_items: {len(item_enc.classes_)}\\n\")\n",
    "        f.write(f\"num_stores: {len(store_enc.classes_)}\\n\")\n",
    "        f.write(f\"feature_cols: {feature_cols}\\n\")\n",
    "except PermissionError as e:\n",
    "    print(f\"PermissionError: Unable to write to 'model_params.txt'. Check file permissions or if the file is in use: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error while writing to 'model_params.txt': {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
