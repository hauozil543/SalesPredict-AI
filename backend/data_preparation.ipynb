{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "345950bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle\n",
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "013562ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đảm bảo thư mục utils tồn tại để lưu scaler\n",
    "if not os.path.exists('utils'):\n",
    "    os.makedirs('utils')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f2d8ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Định nghĩa hàm reduce_mem_usage\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics: \n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "396e148c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bước 1: Tải dữ liệu\n",
    "def load_data():\n",
    "    sales = pd.read_csv('C:/Users/Ho Hau/Downloads/M5/data/raw/sales_train_validation.csv')\n",
    "    prices = pd.read_csv('C:/Users/Ho Hau/Downloads/M5/data/raw/sell_prices.csv')\n",
    "    calendar = pd.read_csv('C:/Users/Ho Hau/Downloads/M5/data/raw/calendar.csv')\n",
    "    \n",
    "    sales = reduce_mem_usage(sales)\n",
    "    prices = reduce_mem_usage(prices)\n",
    "    calendar = reduce_mem_usage(calendar)\n",
    "    \n",
    "    return sales, prices, calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2bf912c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bước 2: Lọc dữ liệu cho bang California và 3 năm gần nhất (2013-2016)\n",
    "def filter_data(sales, calendar):\n",
    "    sales_ca = sales[sales['state_id'] == 'CA']\n",
    "    \n",
    "    start_date = '2013-01-01'\n",
    "    end_date = '2016-05-22'\n",
    "    calendar['date'] = pd.to_datetime(calendar['date'])\n",
    "    calendar_filtered = calendar[(calendar['date'] >= start_date) & (calendar['date'] <= end_date)]\n",
    "    \n",
    "    day_columns = [col for col in sales.columns if col.startswith('d_')]\n",
    "    day_to_date = calendar.set_index('d')['date'].to_dict()\n",
    "    selected_days = [d for d in day_columns if day_to_date.get(d, pd.Timestamp('1900-01-01')) >= pd.Timestamp(start_date)]\n",
    "    \n",
    "    sales_columns = ['item_id', 'store_id', 'cat_id', 'state_id'] + selected_days\n",
    "    sales_ca = sales_ca[sales_columns]\n",
    "    \n",
    "    print(\"Data filtered successfully!\")\n",
    "    print(f\"sales_ca shape: {sales_ca.shape}\")\n",
    "    print(f\"calendar_filtered shape: {calendar_filtered.shape}\")\n",
    "    print(f\"Number of selected days: {len(selected_days)}\")\n",
    "    \n",
    "    return sales_ca, calendar_filtered, selected_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1edc882d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bước 3: Chọn top 100 sản phẩm có doanh số cao nhất\n",
    "def select_top_products(sales_ca, selected_days):\n",
    "    sales_sums = sales_ca[selected_days].sum(axis=1)\n",
    "    sales_ca['total_sales'] = sales_sums\n",
    "    top_products = sales_ca.nlargest(100, 'total_sales')['item_id'].values\n",
    "    sales_top = sales_ca[sales_ca['item_id'].isin(top_products)]\n",
    "    sales_top = sales_top.drop(columns=['total_sales'])\n",
    "    # In thông tin chi tiết của top 100 sản phẩm\n",
    "    print(\"Top 100 sản phẩm bán chạy nhất:\")\n",
    "    top_sales_details = sales_ca[sales_ca['item_id'].isin(top_products)][['item_id', 'total_sales']].drop_duplicates()\n",
    "    for index, row in top_sales_details.iterrows():\n",
    "        print(f\"Item ID: {row['item_id']}, Tổng doanh số: {row['total_sales']}\")\n",
    "    print(\"Top products selected successfully!\")\n",
    "    print(f\"sales_top shape: {sales_top.shape}\")\n",
    "    print(f\"Number of top products: {len(top_products)}\")\n",
    "    \n",
    "    return sales_top, top_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dca62987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bước 4: Kỹ thuật hóa đặc trưng\n",
    "def engineer_features(sales_top, prices, calendar_filtered, selected_days):\n",
    "    id_columns = ['item_id', 'store_id', 'cat_id', 'state_id']\n",
    "    sales_melted = pd.melt(\n",
    "        sales_top,\n",
    "        id_vars=id_columns,\n",
    "        value_vars=selected_days,\n",
    "        var_name='d',\n",
    "        value_name='sales'\n",
    "    )\n",
    "    \n",
    "    sales_melted = sales_melted.merge(\n",
    "        calendar_filtered[['d', 'date', 'wm_yr_wk', 'weekday', 'snap_CA', 'event_name_1', 'event_name_2']],\n",
    "        on='d',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    sales_melted = sales_melted.merge(\n",
    "        prices[prices['store_id'].str.contains('CA')][['store_id', 'item_id', 'wm_yr_wk', 'sell_price']],\n",
    "        on=['store_id', 'item_id', 'wm_yr_wk'],\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Xử lý NaN trong sell_price\n",
    "    original_len = len(sales_melted)\n",
    "    sales_melted['sell_price'] = sales_melted.groupby('item_id')['sell_price'].transform(lambda x: x.fillna(x.mean()))\n",
    "    sales_melted = sales_melted.dropna(subset=['sell_price'])\n",
    "    print(f\"Dropped {original_len - len(sales_melted)} rows due to NaN in sell_price\")\n",
    "    \n",
    "    # Thêm đặc trưng day_of_week\n",
    "    sales_melted['day_of_week'] = sales_melted['weekday'].map({\n",
    "        'Monday': 0, 'Tuesday': 1, 'Wednesday': 2, 'Thursday': 3,\n",
    "        'Friday': 4, 'Saturday': 5, 'Sunday': 6\n",
    "    })\n",
    "    \n",
    "    # Thêm đặc trưng is_holiday\n",
    "    sales_melted['is_holiday'] = sales_melted[['event_name_1', 'event_name_2']].notnull().any(axis=1).astype(int)\n",
    "    \n",
    "    # Thêm đặc trưng month và day_of_month\n",
    "    sales_melted['month'] = sales_melted['date'].dt.month\n",
    "    sales_melted['day_of_month'] = sales_melted['date'].dt.day\n",
    "    \n",
    "    # Thêm các đặc trưng lag và rolling mean\n",
    "    sales_melted = sales_melted.sort_values(['item_id', 'store_id', 'date'])\n",
    "    for lag in [7, 14, 28]:\n",
    "        sales_melted[f'sales_lag_{lag}'] = sales_melted.groupby(['item_id', 'store_id'])['sales'].shift(lag)\n",
    "    \n",
    "    for window in [7, 14]:\n",
    "        sales_melted[f'sales_roll_mean_{window}'] = sales_melted.groupby(['item_id', 'store_id'])['sales'].shift(1).rolling(window=window).mean()\n",
    "    \n",
    "    # Xử lý NaN do lag và rolling mean\n",
    "    sales_melted = sales_melted.fillna(0)\n",
    "    \n",
    "    # Danh sách các đặc trưng\n",
    "    features = ['sales', 'sell_price', 'day_of_week', 'snap_CA', 'is_holiday', 'month', 'day_of_month',\n",
    "                'sales_lag_7', 'sales_lag_14', 'sales_lag_28', 'sales_roll_mean_7', 'sales_roll_mean_14']\n",
    "    sales_melted = sales_melted[['item_id', 'store_id', 'date'] + features]\n",
    "    \n",
    "    print(\"Feature engineering completed!\")\n",
    "    print(f\"sales_melted shape: {sales_melted.shape}\")\n",
    "    \n",
    "    return sales_melted, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4885fdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bước 5: Chuẩn hóa và lưu vào SQLite\n",
    "def save_to_sqlite(sales_melted, features):\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_data = scaler.fit_transform(sales_melted[features])\n",
    "    sales_melted[features] = scaled_data\n",
    "    \n",
    "    conn = sqlite3.connect('historical_data.db')\n",
    "    sales_melted.to_sql('historical_data', conn, if_exists='replace', index=False)\n",
    "    conn.close()\n",
    "    \n",
    "    with open('utils/scaler.pkl', 'wb') as f:\n",
    "        pickle.dump(scaler, f)\n",
    "    \n",
    "    print(\"Data preprocessing completed and saved to SQLite.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c436d99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 95.00 Mb (78.7% reduction)\n",
      "Mem. usage decreased to 130.48 Mb (37.5% reduction)\n",
      "Mem. usage decreased to  0.12 Mb (41.9% reduction)\n",
      "Data filtered successfully!\n",
      "sales_ca shape: (12196, 1214)\n",
      "calendar_filtered shape: (1238, 14)\n",
      "Number of selected days: 1210\n",
      "Top products selected successfully!\n",
      "sales_top shape: (252, 1214)\n",
      "Number of top products: 100\n",
      "Dropped 0 rows due to NaN in sell_price\n",
      "Feature engineering completed!\n",
      "sales_melted shape: (304920, 15)\n",
      "Data preprocessing completed and saved to SQLite.\n"
     ]
    }
   ],
   "source": [
    "# Hàm chính\n",
    "def main():\n",
    "    sales, prices, calendar = load_data()\n",
    "    sales_ca, calendar_filtered, selected_days = filter_data(sales, calendar)\n",
    "    sales_top, top_products = select_top_products(sales_ca, selected_days)\n",
    "    sales_melted, features = engineer_features(sales_top, prices, calendar_filtered, selected_days)\n",
    "    save_to_sqlite(sales_melted, features)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
